{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF 5520 Mandatory term project 2021 - part II\n",
    "\n",
    "# Feature evaluation and classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this mandatory exercise you are going to implement a multivariate Gaussian classifier and use it to classifiy images with 4 different texture classes. You must implement your own classifier, but you are allowed to use library functions to invert matrixes, compute the determinant, and compute the mean vector and the covariance matrix for each class. It is recommended that you use an environment where you have access to a numerically stable library function for matrix inversion (for example Matlab).\n",
    "\n",
    "The exercise combines feature evaluation, classifier implementation, training a classifier, testing different feature combinations and evaluating classifier performance.\n",
    "\n",
    "### Submission through notebook\n",
    "If you submit using a Jupyter notebook, you notebook MUST contain discussion of the required aspect, figures, code, and discussion of what the figures show. Create a zip-file of all materials and check that it displays correctly if downloaded from a differnet directory.  The format of the text should be like what you find in a techinical report.\n",
    "\n",
    "### Time table:\n",
    "• Exercise and images available: Monday October 19, 2020\n",
    "• Deadline for Part II:  Monday November 9, 2020\n",
    "\n",
    "### Submission:\n",
    "Your solution should be submitted as a single PDF file contraining the problem descrition, discussion, and supporting source code. The files should be compressed (.zip or .tar) in a folder names YOURUSERNAME_PARTII.zip/tar and upload it through the devilry system (devilry.ifi.uio.no) before the deadline above. Questions about the submission can be directed to the group teacher.\n",
    "\n",
    "If you submit a notebook, you do not need to include all the original texture images, but make sure to include any result figures or illustions on .png-format.\n",
    "\n",
    "### Evaluation:\n",
    "Since image processing is a field where solutions often are found by experimenting\n",
    "with different methods, we would like to emphasize the following point: You will be\n",
    "credited for analyzing the problem and the input images so you can select suitable\n",
    "methods and features. You will not be credited for testing all available\n",
    "methods/features, even if it is a huge amount of work. Analysis and discussion, of\n",
    "both input and output, are very important. Please note that both mandatory exercises must be passed in order to take the exam.\n",
    "\n",
    "### How to work\n",
    "The exercise is an individual work, and each student should deliver a written report. Your report should be genuine, in particular we will check that each report provides its own discussion of all method and parameter choices. Include references if you use external sources.\n",
    "The report should contain the description of the problem, theory, chosen methods, results and algorithms used. You have to document all steps in the algorithms, and listings of our own code should be included as appendix. The code for your classification algorithm should be listed in your report.\n",
    "Remark: Part II is not linked directly to part I, so you will work on new feature images. These will be input to multivariate classification, not thresholded as in part I. \n",
    "\n",
    "### The image data set\n",
    "\n",
    "#### Python comment: png-version of the dataset is found under …/undervisningsmateriale/mandatory2/oblig2-python.zip\n",
    "Note that the png-format does not handle the scaling of the glcm-images well, thus we work either directly by reading matlab-files or text/ascii-files into python.\n",
    "\n",
    "You have available a separate training data set and a test data set of three original images and a set of precomputed GLCM matrices computed from the training image.\n",
    "The images can be found under …/undervisningsmateriale/mandatory2/oblig2_python.zip . \n",
    "\n",
    "(File extention .txt for text files)\n",
    "Training data set:\n",
    "mosaic1_train.mat\n",
    "training_mask.mat\n",
    "                                                                 For each texture: \n",
    "texture1_glcmdx0dymin1.mat\t \tAngle 90 degrees x, y-1\n",
    "texture1_glcmdxplus1dy0.mat                 Angle 0     x+1,y\n",
    "texture1_glcmdxplus1dymin1.mat          Angle 45 x+1,y-1\n",
    "  texture1_glcmdxmin1dymin1.mat           Angle 135 x-1,y-1\n",
    "texture2_glcmdx0dymin1.mat            .\n",
    "texture2_glcmdxplus1dy0.mat\n",
    "texture2_glcmdxplus1dymin1.mat\n",
    "texture2_glcmdxmin1dymin1.mat\n",
    "texture3_glcmdx0dymin1.mat\n",
    "texture3_glcmdxplus1dy0.mat\n",
    "texture3_glcmdxplus1dymin1.mat\n",
    "texture3_glcmdxmin1dymin1.mat\n",
    "texture4_glcmdx0dymin1.mat\n",
    "texture4_glcmdxplus1dy0.mat\n",
    "texture4_glcmdxplus1dymin1.mat\n",
    "texture4_glcmdxmin1dymin1.mat\n",
    "\n",
    "Test data set:\n",
    "mosaic2_test.mat with mask mask_mosaic2_test.mat \n",
    "mosaic3_test.mat with mask mask_mosaic3_test.mat\n",
    "\n",
    "### Task overview\n",
    "\n",
    "The task has the following steps\n",
    "1. Choosing glcm images to work with.\n",
    "2. Discussing new features by subdividing the GLCM matrices\n",
    "3. Selecting and implementing the best features from the GLCM matrices\n",
    "4. Implementing a Gaussian classifier\n",
    "5. Training the classifier on the chosen features\n",
    "6. Classifying the test images. Compute the classification accuracy and           confusion matrices and discuss the performance of the classification\n",
    "\n",
    "Your report should contain one section for each of these 6 tasks. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choosing GLCM images to work with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mosaic1_train.mat contains 4 differenttextures (texture1,…texture4). A subimage of each texture was used to precompute GLCM matrices as you did in Part I. GLCM matrices with distances $(\\Delta x=1,\\Delta y=0), (\\Delta x=0, \\Delta y=-1), (\\Delta x=1, \\Delta y=-1) and (\\Delta x=-1, \\Delta y=-1)$ for each texture, and G=16. These GLCM images are given above. \n",
    "Analyze the GLCM matrices given and select maximum two directions that you expect to be useful for discriminating the textures. Discuss if you need one or two directions, and discuss which directions you think have most information. \n",
    "\n",
    "Your answer should contain both a discussion and figures to support you discussion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Discussing new features by subdividing the GLCM matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you should NOT use any of the GLCM features from the lectures, but\n",
    "implement your own features that are based on only parts of the GLCM matrices, not the entire matrix. Divide the 16x16 GLCM (G=16) matrix into four quadrants Q1, Q2, Q3 and Q4 of the same size. Create new features by summing the amount of energy/percentage of gray level transitions found in each quadrant, e.g.\n",
    "\n",
    "\\begin{align}\n",
    "Q1=\\frac{\\sum_{i=1}^{8}\\sum_{j=1}^{8}P(i,j)}{\\sum_{i=1}^{G}\\sum_{j=1}^{G}P(i,j)} \n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "Q2=\\frac{\\sum_{i=1}^{8}\\sum_{j=9}^{G}P(i,j)}{\\sum_{i=1}^{G}\\sum_{j=1}^{G}P(i,j)} \n",
    "\\end{align}\n",
    " \n",
    "Features Q3 and Q4 should be computed correspondingly.\n",
    "\n",
    "Based on just visual inspection of the selected GLCM matrices, discuss if you think all four textures can be separated with these features. If you do not think the textures can be separated using a subdivision into 4 quadrants, you can subdivide ONE of the quadrants into 4 smaller quadrants of equal size. If you choose to do this, discuss which quadrant you should subdivide.\n",
    "\n",
    "How many quadrants do you need do discriminate between the four textures? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Selecting and implementing a subset of these features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the features chosen in step 2 using sliding windows of size 31x31, G=16, and the direction(s) you chose. Consider all your features but discuss if you will need all of them in the classification. Select some of the features and include the corresponding feature images computed from mosaic1_train.mat in your report.\n",
    "\n",
    "Your answer must contain code, discussion, and figures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement a multivariate Gaussian classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier can and should use library functions for matrix inversion and computing the determinant. If you want, you can use library functions for estimating the mean vector and the covariance matrix. However, you must implement the computation of the posterior probability using Bayes rule yourself. Include the classifier code below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the classifier based on the feature subset from point 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the overall classification accuracy and the full confusion matrix based on the training data. Discuss the performance, what does the confusion matrix show?\n",
    "(Hint: if you run into a singular covariance matrix using a certain combination of features, there might be a reason for that. Try to understand why. If you don’t run into singular matrices you feature selection has avoided this little “trap”.)\n",
    "\n",
    "Include the results and discussion below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation of classification performance on the test data set using the set of features selected in point 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the overall classification accuracy and the confusion matrix on the two test images. These images are slightly different from the training image. Include the results and some discussion below. \n",
    "\n",
    "Compute the accuracy both on mosaic2_test.mat and mosaic3_test.mat using the corresponding test masks mask_mosaic2_test.mat and mask_mosaic3_test.mat. Compare the performance, and discuss the differences in accuracy you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Voluntary extension:\n",
    "Train using a library function for another classifier (e.g. knn  or SVM). Train on mosaic1_train. Use mosaic2_test as validation dataset (e.g. for hyperparameter selection), and present your results on mosaic3_test. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
